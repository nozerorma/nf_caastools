#!/usr/bin/env nextflow

/*
#                          _              _
#                         | |            | |
#      ___ __ _  __ _ ___| |_ ___   ___ | |___
#    / __/ _` |/ _` / __| __/ _ \ / _ \| / __|
#   | (_| (_| | (_| \__ \ || (_) | (_) | \__ \
#   \___\__,_|\__,_|___/\__\___/ \___/|_|___/
#
# A Convergent Amino Acid Substitution identification 
# and analysis toolbox
#
# Author:         Fabio Barteri (fabio.barteri@upf.edu)
# Contributors:   Alejandro Valenzuela (alejandro.valenzuela@upf.edu),
#                 Xavier FarrÃ© (xfarrer@igtp.cat),
#                 David de Juan (david.juan@upf.edu),
#                 Miguel Ramon (miguel.ramon@upf.edu) - Nextflow Protocol Elaboration
#
# File: nextflow.config
#
*/

/*
 * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 * Configuration file for setting up global parameters, process-specific resource requirements, 
 * and execution profiles. This ensures optimal resource allocation and flexibility across 
 * different compute environments.
 * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 */
process.container           = 'miralnso/caastools-micromamba:latest'

// Redirect logs to stable log dir: $ export NXF_LOG_FILE="log/nextflow.log" (must be set in console before running the script)

// Global default params, used in configs
params {

    // CT general option
    ct_tool                     = ct_tool                   ?:  "discovery,resample,bootstrap"

    // Common DISCOVERY and BOOTSTRAP options
    alignment                   = alignment                 ?:  "$baseDir/Data/Primate_alignments"
    disc_description            = disc_description          ?:  null
    traitfile                   = traitfile                 ?:  "$baseDir/Out/4.CAAS_analysis/config.tab"
    ali_format                  = ali_format                ?:  "phylip-relaxed"
    // clustal, emboss, fasta, fasta-m10, ig, maf, mauve, msf, nexus, phylip, phylip-sequential, phylip-relaxed, stockholm
    patterns                    = patterns                  ?:  "1,2,3"
    maxbggaps                   = maxbggaps                 ?:  "NO"  
    maxfggaps                   = maxfggaps                 ?:  "NO"
    maxgaps                     = maxgaps                   ?:  "NO"
    maxgapsperposition          = maxgapsperposition        ?:  "0.5"
    maxbgmiss                   = maxbgmiss                 ?:  "NO"
    maxfgmiss                   = maxfgmiss                 ?:  "NO"
    maxmiss                     = maxmiss                   ?:  "NO"

    // RESAMPLE options
    tree                       = tree                       ?:  "$baseDir/Data/233-GENOMES/science.abn7829_data_s4.nw.tree"
    strategy                   = strategy                   ?:  "FGBG"
    fgsize                     = fgsize                     ?:  "6"
    bgsize                     = bgsize                     ?:  "6"
    template                   = template                   ?:  null
    bygroup                    = bygroup                    ?:  null
    traitvalues                = traitvalues                ?:  null
    cycles                     = cycles                     ?:  "500"
    
    // BOOTSTRAP options
    resample_out               = resample_out               ?:  null

    // Boilerplate options
    outdir                     = outdir                     ?: "$baseDir/Out/4.CAAS_analysis/CAASresults"
    monochrome_logs            = false
    hook_url                   = null
    help                       = false
    version                    = false


    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = max_memory                 ?:  "4.GB"
    max_cpus                   = max_cpus                   ?:  4
    max_time                   = max_time                   ?:  "24.h"

}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'


profiles {
    debug {
        dumpHashes             = true
        process.beforeScript   = 'echo $HOSTNAME'
        cleanup                = false
    }
    conda {
        conda.enabled          = true
        conda.cacheDir         = "$baseDir/conda"
        docker.enabled         = false
        podman.enabled         = false
        singularity.enabled    = false
    }
    mamba {
        conda.enabled          = true
        conda.useMicromamba    = true
        conda.cacheDir         = "$baseDir/mamba"
        docker.enabled         = false
        podman.enabled         = false
        singularity.enabled      = false
    }
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        conda.enabled          = false
        podman.enabled         = false
        singularity.enabled    = false
    }
    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    podman {
        podman.enabled         = true
        conda.enabled          = false
        docker.enabled         = false
        podman.enabled         = true
        singularity.enabled    = false
    }
    singularity {
        singularity.enabled         = true
        singularity.autoMounts      = true
        singularity.cacheDir        = "$baseDir/singularity"
        docker.enabled              = false
        podman.enabled              = false
    }
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')

timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    trace.overwrite = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}


manifest {
    name            = 'nf-caastools'
    author          = """Miguel Ramon Alonso"""
    homePage        = 'https://github.com/nozerorma/caastools'
    description     = """Nexflow pipeline for running CAAStools analyses"""
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.04.0'
    version         = '1.0'
    doi             = ''
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

profiles {
  standard {
     process {
        executor="local"
        workDir = '$baseDir/work'

        withLabel: big_mem {
            cpus = "${params.max_cpus}"
            memory = "${params.max_memory}"
            time = "${params.max_time}"
        }
    }
   }

   cluster {
     process {  
        workDir = '$baseDir/work'
        executor = "slurm"

        withLabel: big_mem {
            cpus = "${params.max_cpus}"
            memory = "${params.max_memory}"
            time = "${params.max_time}"
        }
      }
   }

   cloud {
    workDir = 's3://nf-class-bucket-XXX/work'
    aws.region = 'eu-central-1'
    aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'

   process {
       executor = 'awsbatch'
       queue = 'spot'
       memory='1G'
       cpus='1'
       time='6h'

       withLabel: 'twocpus' {
           memory='2G'
           cpus='2'
       }
    }
  }
}
